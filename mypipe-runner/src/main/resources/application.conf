mypipe {

  # consumers represent sources for mysql binary logs
  enable-avro-gen = false

  consumers {

    database1 {
      # database "host:port:user:pass" array
      source = "127.0.0.1:3307:root:root"
    }

  }

  # data producers export data out (stdout, other stores, external services, etc.)
  producers {

    stdout {
      class = "mypipe.producer.stdout.StdoutProducer"
    }

    kafka-generic {
      class = "mypipe.producer.KafkaMutationGenericAvroProducer"
    }

    kafka-specific{
      class = "mypipe.producer.KafkaMutationSpecificAvroProducer"
    }

    confluent{
      class = "mypipe.producer.ConfluetProducer"
    }

    kafka-json{
      class = "mypipe.producer.KafkaJsonProducer"
    }

    stdout-json{
      class = "mypipe.producer.stdout.StdoutJsonProducer"
    }

  }

  # pipes join consumers and producers,
  # each pipe can connect many consumers to one producer[not vce versa]
  # if you want to connect one consumer with many producers,make as many many pipes as needed.
  pipes {
    #pipe obj
    stdout {
      #consumers obj

      consumers {
        database1 {

          #if customBinLog is not given default is false
          #if customBinLog = true,we should always mention binlogFileName,binlogPosition.
          #If they are not given default is current position of binlog in mysql server
          customBinLog = false
          #name format = "mysql-bin.000001"
          binlogFileName = "mysql-bin.000001"
          #pos should be a long
          binLogPosition = 120
        }
      }
      #producer obj
      producer {
        stdout {}
      }
    }

    kafka-generic {
      enabled = false
      consumers {
        database1 {
          customBinLog = false
          binlogFileName = "mysql-bin.000001"
          binLogPosition = 120
        }
      }
      producer {
        kafka-generic {
          metadata-brokers = "localhost:9092"
        }
      }
    }

    kafka-specific {
      enabled = false
      consumers {
        database1 {
          customBinLog = false
        }
      }
      producer {
        kafka-specific {
          schema-repo-client = "localhost:8081"
          metadata-brokers = "localhost:9092"
          zk-connect = "localhost:2181"
        }
      }
    }

    kafka-json {
      enabled = true
      consumers {
        database1 {
          customBinLog = false
        }
      }
      producer {
        kafka-json{
          schema-repo-client = "localhost:8081"
          metadata-brokers = "localhost:9092"
          zk-connect = "localhost:2181"
        }
      }
    }

    confluent {
      enabled = false
      consumers {
        database1 {
          customBinLog = false
        }
      }
      producer {
        confluent {
          schema-repo-client = "http://localhost:8081"
          metadata-brokers = "localhost:9092"
          zk-connect = "localhost:2181"
          avro-schemas-path = "./avro-schemas/"
        }
      }
    }

    stdout-json {
      enabled = true
      consumers {
        database1 {
          customBinLog = false
        }
      }
      producer {
        stdout-json {
        }
      }
    }



  }

}

include "application.overrides"
